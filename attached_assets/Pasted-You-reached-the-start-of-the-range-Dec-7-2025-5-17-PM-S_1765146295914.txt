You reached the start of the range
Dec 7, 2025, 5:17 PM
Starting Container
Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.
  You can now view your Streamlit app in your browser.
  URL: http://0.0.0.0:8080
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
‚ö†Ô∏è Vendor name 'LYNX FINHEALTH, INC.' (normalized: 'LYNX FINHEALTH, INC.') not found in contract text
INFO:pages.memo_review_job_runner:Memo Review job submitted: 114
INFO:shared.api_cost_tracker:API cost tracker reset
INFO:shared.job_manager:Routing to memo review worker for ASC 606
INFO:shared.job_manager:‚úì Job submitted for ASC 606: 114 (analysis 114)
INFO:shared.analysis_manager:ANALYSIS_EVENT: {"event_type": "start", "timestamp": "2025-12-07T22:22:57.982664", "analysis_id": "bac4450b", "asc_standard": "ASC 606", "total_words": 58961, "file_count": 4, "tier": null, "cost": 0.0, "user_id": 20, "status": "running", "success": null, "duration": null, "error": null}
INFO:shared.analysis_manager:Started analysis bac4450b: ASC 606 - 58961 words
INFO:pages.memo_review_job_runner:Started Memo Review analysis tracking: UI ID=bac4450b, DB ID=114, Job ID=114
INFO:shared.job_progress_monitor:Job 114 status: JobStatus.QUEUED
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
Failed to get encoding for model gpt-5-mini, using default: 'Could not automatically map gpt-5-mini to a tokeniser. Please use `tiktok.get_encoding` to explicitly get the tokeniser you expect.'
‚ö†Ô∏è Vendor name 'LYNX FINHEALTH, INC.' (normalized: 'LYNX FINHEALTH, INC.') not found in contract text
INFO:shared.job_progress_monitor:Job 114 status: JobStatus.STARTED
           ^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py", line 1192, in create
    return self._post(
           ^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1259, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/openai/_base_client.py", line 1047, in request
    raise self._make_status_error_from_response(err.response) from None
INFO:shared.job_progress_monitor:Job 114 status: JobStatus.FAILED
ERROR:shared.job_progress_monitor:Job 114 failed: Traceback (most recent call last):
  File "/app/asc606/step_analyzer.py", line 636, in _analyze_step_with_retry
    result = self._analyze_step(
             ^^^^^^^^^^^^^^^^^^^
  File "/app/asc606/step_analyzer.py", line 751, in _analyze_step
    response = self.client.chat.completions.create(**request_params)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py", line 286, in wrapper
    return func(*args, **kwargs)
openai.BadRequestError: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/app/workers/analysis_worker.py", line 1279, in run_memo_review_analysis
    step_result = analyzer._analyze_step_with_retry(
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/asc606/step_analyzer.py", line 687, in _analyze_step_with_retry
    raise RuntimeError(f"OpenAI API error: {str(e)}")
RuntimeError: OpenAI API error: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File "/usr/local/lib/python3.11/site-packages/rq/worker.py", line 1439, in perform_job
    return_value = job.perform()
                   ^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/rq/job.py", line 1318, in perform
                   ^^^^^^^^^^^^^^^
  File "/usr/local/lib/python3.11/site-packages/rq/job.py", line 1376, in _execute
    result = self.func(*self.args, **self.kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/app/workers/analysis_worker.py", line 1292, in run_memo_review_analysis
    raise Exception(f"Step {step_num} failed: {str(e)}")
Exception: Step 1 failed: OpenAI API error: Error code: 400 - {'error': {'message': "Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}
INFO:shared.analysis_manager:üíæ Saving analysis record: bac4450b
INFO:shared.analysis_manager:Current auth token is valid
INFO:shared.analysis_manager:‚úì Analysis saved to database: bac4450b
INFO:shared.analysis_manager:ANALYSIS_EVENT: {"event_type": "complete", "timestamp": "2025-12-07T22:23:18.310037", "analysis_id": "bac4450b", "asc_standard": "ASC 606", "total_words": 58961, "file_count": 4, "tier": null, "cost": 0.0, "user_id": 20, "status": "failed", "success": false, "duration": 20.04700994491577, "error": "Traceback (most recent call last):\n  File \"/app/asc606/step_analyzer.py\", line 636, in _analyze_step_with_retry\n    result = self._analyze_step(\n             ^^^^^^^^^^^^^^^^^^^\n  File \"/app/asc606/step_analyzer.py\", line 751, in _analyze_step\n    response = self.client.chat.completions.create(**request_params)\n               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_utils/_utils.py\", line 286, in wrapper\n    return func(*args, **kwargs)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/resources/chat/completions/completions.py\", line 1192, in create\n    return self._post(\n           ^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1259, in post\n    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/openai/_base_client.py\", line 1047, in request\n    raise self._make_status_error_from_response(err.response) from None\nopenai.BadRequestError: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/app/workers/analysis_worker.py\", line 1279, in run_memo_review_analysis\n    step_result = analyzer._analyze_step_with_retry(\n                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/asc606/step_analyzer.py\", line 687, in _analyze_step_with_retry\n    raise RuntimeError(f\"OpenAI API error: {str(e)}\")\nRuntimeError: OpenAI API error: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/usr/local/lib/python3.11/site-packages/rq/worker.py\", line 1439, in perform_job\n    return_value = job.perform()\n                   ^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/rq/job.py\", line 1318, in perform\n    self._result = self._execute()\n                   ^^^^^^^^^^^^^^^\n  File \"/usr/local/lib/python3.11/site-packages/rq/job.py\", line 1376, in _execute\n    result = self.func(*self.args, **self.kwargs)\n             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/app/workers/analysis_worker.py\", line 1292, in run_memo_review_analysis\n    raise Exception(f\"Step {step_num} failed: {str(e)}\")\nException: Step 1 failed: OpenAI API error: Error code: 400 - {'error': {'message': \"Unsupported parameter: 'max_tokens' is not supported with this model. Use 'max_completion_tokens' instead.\", 'type': 'invalid_request_error', 'param': 'max_tokens', 'code': 'unsupported_parameter'}}\n"}
    self._result = self._execute()
INFO:shared.analysis_manager:Completed analysis bac4450b: failed - 20.0s