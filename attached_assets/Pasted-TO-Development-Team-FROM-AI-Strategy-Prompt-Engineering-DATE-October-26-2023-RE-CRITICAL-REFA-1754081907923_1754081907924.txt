TO: Development Team FROM: AI Strategy & Prompt Engineering DATE: October 26, 2023 RE: CRITICAL REFACTOR: Decomposing step_prompts.py for Improved LLM Adherence and Maintainability

1. Overview & Problem Statement
The team has done an exceptional job creating highly detailed and specific prompts for the ASC 606 analysis. However, as the prompts in step_prompts.py have grown, we've created a "mega-prompt" in get_step_specific_analysis_prompt that is now so long and dense that the LLM is beginning to struggle.

This "instruction dilution" causes the model to occasionally ignore critical rules buried in the middle of the prompt, leading to inconsistent and sometimes incorrect output. The current approach is not sustainable and makes debugging and future enhancements difficult.

2. The Solution: Decompose and Structure
The solution is not to remove our detailed instructions, but to refactor them using a more robust, modular approach inspired by software engineering principles. We will move from a single, monolithic prompt to a System/User prompt architecture.

System Prompt: A static set of high-level instructions that defines the AI's core persona, its non-negotiable rules, and its required output format. This is sent with every call.
User Prompt: A dynamic, concise prompt that provides the specific context for the task at hand (the contract text, the current analysis step, and only the most critical rules for that specific step).
This change will make our instructions clearer to the LLM, dramatically improve its adherence to our rules, and make the prompt logic far easier to maintain and debug.

3. Implementation Plan: The New StepPrompts Class
Please replace the entire StepPrompts class in utils/step_prompts.py with the following refactored code. The new class breaks down the monolithic prompt into smaller, single-purpose, and more effective functions.

I have preserved the core logic and wording of the original prompts wherever possible, but reorganized them for maximum clarity and impact on the LLM.

# In utils/step_prompts.py
# --- Start of new code ---

import json

class StepPrompts:
    """
    Refactored prompts using a modular, System/User architecture to improve LLM adherence.
    This approach separates the AI's core instructions (System Prompt) from the
    dynamic task-specific instructions (User Prompt).
    """

    @staticmethod
    def get_step_info() -> dict:
        """Returns information about each ASC 606 step. (No changes needed here)"""
        return {
            1: {"title": "Identify the Contract", "primary_guidance": "ASC 606-10-25-1 through 25-8"},
            2: {"title": "Identify Performance Obligations", "primary_guidance": "ASC 606-10-25-14 through 25-22"},
            3: {"title": "Determine the Transaction Price", "primary_guidance": "ASC 606-10-32-2 through 32-27"},
            4: {"title": "Allocate the Transaction Price", "primary_guidance": "ASC 606-10-32-28 through 32-41"},
            5: {"title": "Recognize Revenue", "primary_guidance": "ASC 606-10-25-23 through 25-37"}
        }

    # --- NEW: Core Prompt Architecture ---

    @staticmethod
    def get_system_prompt() -> str:
        """
        Defines the AI's core persona, universal rules, and mandatory output format.
        This is static and sent with every step-analysis call.
        """
        return """You are an expert technical accountant specializing in ASC 606. Your analysis must be audit-ready, precise, and objective. You must follow all instructions and formatting rules precisely.

<OUTPUT_FORMAT_RULE>
You MUST return your response as a single, well-formed JSON object. Do not add any text, explanations, or markdown formatting before or after the JSON object. Your entire response must be only the JSON.

The JSON object MUST contain these top-level keys: "executive_conclusion", the relevant "step_X_analysis" block, "professional_judgments", and "analysis_points".
</OUTPUT_FORMAT_RULE>

<EVIDENCE_RULE>
Every quote from the contract provided in the `evidence_quotes` array MUST include the source document name, formatted exactly as: 'Quote text... (Source: [Document Name])'.
</EVIDENCE_RULE>

<ANALYSIS_RULE>
Your analysis must be thorough. Weave in specific ASC 606 citations (e.g., ASC 606-10-25-1) to support your conclusions.
</ANALYSIS_RULE>
"""

    @staticmethod
    def get_user_prompt_for_step(step_number: int, contract_text: str, rag_context: str, contract_data=None, debug_config=None) -> str:
        """
        Builds the dynamic, task-specific user prompt for a single step analysis.
        This is the new replacement for the old get_step_specific_analysis_prompt.
        """
        step_info = StepPrompts.get_step_info()[step_number]
        step_schema_name = f"step{step_number}_analysis"
        step_schema_definition = StepPrompts._get_schema_for_step(step_number)
        critical_rules = StepPrompts._get_critical_rules_for_step(step_number, contract_text)

        # Assemble the concise user prompt
        prompt_parts = [
            f"Your task is to analyze a contract for Step {step_number}: {step_info['title']}.",
            f"PRIMARY GUIDANCE FOR THIS STEP: {step_info['primary_guidance']}",
            f"<AUTHORITATIVE_CONTEXT>\n{rag_context}\n</AUTHORITATIVE_CONTEXT>",
            f"<CONTRACT_TEXT>\n{contract_text}\n</CONTRACT_TEXT>",
            f"<CONTRACT_DATA>\nCustomer: {getattr(contract_data, 'customer_name', 'N/A')}\nAnalysis Focus: {getattr(contract_data, 'key_focus_areas', 'General ASC 606 compliance')}\n</CONTRACT_DATA>",
            "---",
            "CRITICAL TASK: Analyze the contract based on the context provided. Populate the JSON structure below with your complete analysis. Adhere to all rules.",
            "```json",
            "{",
            f'  "executive_conclusion": "A clear, one-to-three sentence conclusion for this entire step. This is the \'bottom line\'.",',
            f'  "{step_schema_name}": {step_schema_definition},',
            '  "professional_judgments": [ "A list of strings describing conclusions that required significant professional judgment for this step. If none, return an empty list []." ],',
            '  "analysis_points": [ { "topic_title": "...", "analysis_text": "...", "evidence_quotes": ["..."] } ]',
            "}",
            "```",
            critical_rules
        ]
        return "\n\n".join(prompt_parts)

    # --- NEW: Modular Helper Functions ---

    @staticmethod
    def _get_schema_for_step(step_number: int) -> str:
        """Helper to route to the correct, existing schema definition."""
        if step_number == 1: return StepPrompts.get_step1_schema()
        if step_number == 2: return StepPrompts.get_step2_schema()
        if step_number == 3: return StepPrompts.get_step3_schema()
        if step_number == 4: return StepPrompts.get_step4_schema()
        if step_number == 5: return StepPrompts.get_step5_schema()
        return "{}"

    @staticmethod
    def _get_critical_rules_for_step(step_number: int, contract_text: str) -> str:
        """Returns a concise block of the most critical, non-negotiable rules for a given step."""
        rules = {
            1: """<CRITICAL_INSTRUCTION>
- You MUST evaluate ALL FIVE criteria from ASC 606-10-25-1(a) through (e) within the `contract_criteria_assessment` array. No shortcuts.
- You MUST create a corresponding `analysis_points` entry for each of the five criteria.
</CRITICAL_INSTRUCTION>""",
            2: """<CRITICAL_INSTRUCTION>
- If no distinct performance obligations are found, `performance_obligations` MUST be an empty list `[]`, and you must explain why in the `analysis_points`.
- For simple contracts with one obvious obligation, keep the analysis concise but complete.
- Focus on the "separately identifiable" criterion, as it is often the most decisive factor.
</CRITICAL_INSTRUCTION>""",
            3: """<CRITICAL_INSTRUCTION>
- Your primary analysis MUST occur within the `transaction_price_components` JSON structure.
- Only use `analysis_points` for truly separate or unusual considerations not already covered by the standard components.
</CRITICAL_INSTRUCTION>""",
            4: """<CRITICAL_INSTRUCTION>
- If there is only one performance obligation identified in Step 2, the `analysis_points` array MUST be empty `[]`. The `step4_overall_conclusion` is sufficient.
- Do NOT re-identify or re-analyze performance obligations or the transaction price in this step. Simply reference the POs from Step 2.
</CRITICAL_INSTRUCTION>""",
            5: """<CRITICAL_INSTRUCTION>
- You MUST provide detailed analysis in both the `revenue_recognition_plan` and `analysis_points`. Do not use shortcuts like "No additional analysis required".
- The `revenue_recognition_plan` must include a specific `recognition_justification` for each PO, citing which ASC 606-10-25-27 criterion is met for 'Over Time' recognition.
- You must include a `measure_of_progress_analysis` explaining the method used (e.g., straight-line, input/output).
</CRITICAL_INSTRUCTION>"""
        }

        # Special logic for Step 3 to prevent hallucination
        if step_number == 3:
            contract_lower = contract_text.lower()
            is_simple_contract = "subscription" in contract_lower or "fixed fee" in contract_lower
            is_complex_contract = "bonus" in contract_lower or "royalty" in contract_lower or "variable" in contract_lower

            if is_simple_contract and not is_complex_contract:
                return rules[3] + """
<CRITICAL_OVERRIDE>
This appears to be a simple, fixed-price contract. You MUST follow these rules:
- In the `transaction_price_components` JSON, set `variable_consideration` to "N/A".
- The `professional_judgments` array MUST be an empty list `[]`.
- Do NOT invent complexity where none exists.
</CRITICAL_OVERRIDE>"""

        return rules.get(step_number, "")

    # --- Existing Functions (Keep As Is, but make them private if only used by helpers) ---
    # The get_stepX_schema and other prompt functions (get_financial_impact_prompt, etc.)
    # remain the same for now. The focus is on fixing the core analysis step.
    # We are only replacing get_step_specific_analysis_prompt.

    # [ KEEP ALL OTHER FUNCTIONS from the original step_prompts.py here, such as: ]
    # get_financial_impact_prompt, get_conclusion_prompt, get_enhanced_executive_summary_prompt,
    # get_step1_schema, get_step2_schema, get_step3_schema, get_step4_schema, get_step5_schema,
    # and all the _format functions.

# --- End of new code ---

4. How to Integrate the Changes
The new prompt architecture requires a small but critical change in utils/asc606_analyzer.py where the async LLM calls are created.

In the file utils/asc606_analyzer.py, inside the analyze_contract method, locate the loop where asyncio.create_task is called.

Current Code (Around line 285):

# OLD CODE
step_prompt = StepPrompts.get_step_specific_analysis_prompt(
    step_number=step_num,
    # ... other args
)

task = asyncio.create_task(make_llm_call_async(
    self.client,
    step_prompt,
    # ... other args
))

Required Change:

Replace the step_prompt creation and the make_llm_call_async call with the new System/User prompt structure. The make_llm_call_async function needs to be updated to accept messages instead of a single prompt string.

First, update utils/llm.py:

Modify make_llm_call_async to accept a messages list.

# In utils/llm.py

async def make_llm_call_async(
    client,
    messages: List[Dict[str, str]], # CHANGED from prompt: str
    temperature: float = 0.3,
    max_tokens: Optional[int] = None,
    model: str = "gpt-4o",
    response_format: Optional[Dict[str, Any]] = None
) -> Optional[str]:
    """
    Asynchronous version of make_llm_call for concurrent execution
    """
    try:
        # ... (rest of the function is mostly the same)
        # Prepare messages format
        # messages = [{"role": "user", "content": prompt}] # DELETE this line

        # Prepare request parameters
        request_params = {
            "model": model,
            "messages": messages, # This now uses the passed-in messages list
            "temperature": temperature
        }
        # ... (rest of the function is the same)

Second, update utils/asc606_analyzer.py:

# In utils/asc606_analyzer.py, inside the analyze_contract method loop

# NEW CODE
# Prepare the messages list using the new architecture
system_prompt = StepPrompts.get_system_prompt()
user_prompt = StepPrompts.get_user_prompt_for_step(
    step_number=step_num,
    step_title=step_info['title'],
    step_guidance=step_info['primary_guidance'],
    contract_text=contract_text,
    rag_context=retrieved_context + step_specific_context,
    contract_data=contract_data,
    debug_config=debug_config or {}
)

messages = [
    {"role": "system", "content": system_prompt},
    {"role": "user", "content": user_prompt}
]

# Create async task for concurrent execution
task = asyncio.create_task(make_llm_call_async(
    self.client,
    messages, # PASS the messages list here
    temperature=debug_config.get('temperature', 0.3) if debug_config else 0.3,
    max_tokens=debug_config.get('max_tokens', 4000 if step_num == 2 else 3000) if debug_config else (4000 if step_num == 2 else 3000),
    model=debug_config.get('model', 'gpt-4o') if debug_config else 'gpt-4o',
    response_format={"type": "json_object"}
))
tasks.append(task)

5. Summary of Benefits
This refactoring will yield significant benefits:

Improved Reliability: By separating concerns, the LLM will have a much clearer understanding of its core rules versus its specific task, leading to better instruction adherence.
Better Maintainability: Modifying a specific rule for a single step will now involve changing one small, isolated function (_get_critical_rules_for_step) instead of editing a massive, monolithic prompt.
Enhanced Readability: The prompt-building logic is now clean and easy to follow.
Future-Proofing: This modular architecture makes it much easier to add new features or adjust the analysis logic in the future.
Please proceed with implementing these changes. This is the most critical enhancement we can make right now to improve the quality and consistency of our analysis output.

Let me know if you have any questions.