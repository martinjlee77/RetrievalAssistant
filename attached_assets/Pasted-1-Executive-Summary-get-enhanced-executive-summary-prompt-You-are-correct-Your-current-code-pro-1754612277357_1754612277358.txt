1. Executive Summary (get_enhanced_executive_summary_prompt)
You are correct. Your current code programmatically joins the judgments. We need to modify this, but we can't do it with a simple prompt change alone because the Python code itself is assembling the final string.

The best solution is to change what the critical_judgments list contains before it gets to this line. The _filter_genuine_judgments helper function in StepPrompts is where the judgments are being refined. We can modify this slightly, but a better approach is to process the list right inside get_enhanced_executive_summary_prompt.

The Problem: The critical_judgments list currently contains full sentences like: "Determining the likelihood and inclusion of the performance bonus as variable consideration required significant judgment."

The Goal: We want a list of short titles like: "Variable Consideration Estimation".

Recommendation:

We'll use a small, targeted LLM call within the get_enhanced_executive_summary_prompt function to summarize the long judgment sentences into short titles.

Here's the code change:

File: utils/step_prompts.py Function: get_enhanced_executive_summary_prompt

# Inside get_enhanced_executive_summary_prompt, after you create the `critical_judgments` list...

# --- START NEW CODE BLOCK ---

# Check if there are any critical judgments to process
summary_judgment_titles = []
if critical_judgments:
    # Use a small, fast LLM call to summarize the judgment sentences into titles
    summarization_prompt = f"""
    You are a summarization expert. Your task is to convert the following list of detailed accounting judgments into concise, 2-4 word titles for an executive summary.

    JUDGMENT SENTENCES:
    {json.dumps(critical_judgments)}

    Return a simple, pipe-separated list of the titles.
    Example Input: ["Determining the standalone selling price (SSP) for the hardware...", "Allocating the variable consideration..."]
    Example Output: SSP for Hardware | Variable Consideration Allocation
    """

    # This should be a synchronous, simple call. You might need your OpenAI client here.
    # We'll assume a function `make_simple_llm_call` exists for this.
    try:
        # NOTE: You'll need to adapt this to use your actual LLM calling function.
        # This is a conceptual example.
        from utils.llm import make_llm_call, get_openai_client # You may need to import these
        client = get_openai_client()
        messages = [{"role": "user", "content": summarization_prompt}]
        raw_titles = make_llm_call(client, messages, model="gpt-4o-mini", temperature=0.1, max_tokens=100)

        if raw_titles:
            summary_judgment_titles = [title.strip() for title in raw_titles.split('|')]
    except Exception as e:
        # Fallback in case the LLM call fails: use the original long judgments
        summary_judgment_titles = critical_judgments 

# --- END NEW CODE BLOCK ---


# Now, find the line you mentioned and CHANGE it to use the new list
# YOUR CURRENT LINE:
# - **Critical Judgments:** {', '.join(critical_judgments) if critical_judgments else 'None identified'}

# YOUR NEW LINE:
- **Critical Judgments:** {', '.join(summary_judgment_titles) if summary_judgment_titles else 'None identified'}

This is the most robust way to solve it. It keeps your existing logic but adds a summarization layer to generate the concise titles needed for the executive summary.