Subject: Project Plan for New "ASC 340-40 Contract Costs" Module

Hi [Developer's Name],

I hope you're doing well.

We're ready to begin the next phase of our accounting analysis platform by adding our second major feature: an analysis module for ASC 340-40, Other Assets and Deferred Costsâ€”Contracts with Customers.

The goal of this new app is to analyze a specific cost document and generate a professional, audit-ready memo that concludes whether the cost should be capitalized as an asset or expensed immediately.

This project will have two main parts: first, preparing the knowledge base that the AI will use for its analysis, and second, building the application itself.

Task 1: Knowledge Base Preparation (Prerequisite)
This is the foundational step. We need to create a new, dedicated knowledge base for ASC 340-40. I will provide you with two source documents: the official text of ASC 340-40 and an EY interpretative guide on the topic.

Your task is to create a standalone Python script (e.g., scripts/seed_db.py) that is not part of the main Streamlit app. This script will perform a one-time data loading process with the following logic:

Read Source Documents: Use the existing utils/document_extractor.py utility to extract the raw text from the two source files I provide.

Chunk the Text: Process the raw text into smaller, meaningful "chunks" for the vector database.

For the authoritative ASC 340-40 text: The text is structured with paragraph numbers (e.g., 340-40-25-1). Please use these as the chunking delimiter. Each numbered paragraph should be a single, distinct chunk.
For the EY Guide (PDF): The structure will be less defined. Please implement a reasonable chunking strategy, such as splitting the text by paragraph (i.e., splitting on double newlines \n\n).
Generate Metadata: For each chunk, create a precise metadata dictionary. This is critical for filtering and citations.

Authoritative Text Metadata: { "standard": "ASC 340-40", "source_type": "authoritative", "paragraph": "340-40-25-1", ... }
Interpretative Text Metadata: { "standard": "ASC 340-40", "source_type": "interpretative", "source_file": "EY_Guide_Contract_Costs.pdf", ... }
Load into ChromaDB:

Use the utils/knowledge_base_manager.py to get or create a collection for ASC 340-40. The manager is already designed to handle this.
Loop through your prepared chunks and use ChromaDB's collection.add() or collection.upsert() method to load the chunks, their generated embeddings, and their metadata into the database.
Task 2: Refactor for Platform Scalability
With the data prepared, we need to structure the application to handle multiple standards gracefully.

Create main_app.py: This will be our new application entrypoint. It can be a simple landing page that introduces the platform and uses the sidebar for navigation.

Create the pages/ Directory:

Move asc_606_page.py into this directory and rename it to pages/1_ASC_606_Revenue.py.
This will automatically create the multi-page navigation in the sidebar.
Task 3: Build the ASC 340-40 App Module
Now, build the new module using our scalable pattern.

Create the UI (pages/2_ASC_340-40_Contract_Costs.py):

Create this new file by copying the ASC 606 page as a template, but simplify the UI for our 2-phase analysis:
Tab 1 (Cost Details): Inputs for Analysis Title, Customer Name, Cost Description, and a file uploader.
Tab 2 (Provide Context): Inputs for Cost Type (Obtaining/Fulfilling), Recoverability (toggle), and the Amortization Period (number input).
The "Generate Memo" button should instantiate and call the new ASC340Analyzer.
Update core/models.py:

Add two new Pydantic classes: ContractCostData (to match the new UI inputs) and ASC340Analysis (to structure the final output).
Create the Analysis Logic in utils/:

Rename step_prompts.py to step_prompts_606.py and update the corresponding import in asc_606_analyzer.py.
Create utils/step_prompts_340.py. This is the "brain" for the new module. It will contain an ASC340Prompts class with methods to generate prompts for our two phases: (1) Gateway & Scope and (2) Capitalization & Amortization Plan.
Create utils/asc_340_analyzer.py by duplicating the 606 analyzer. Simplify its analyze_contract method to perform a 2-phase loop. Ensure it imports and uses the new ASC340Analysis model and ASC340Prompts class.
Crucially, ensure the RAG call within this new analyzer queries the correct standard: standard="ASC 340-40".
Confirm Reusable Utilities:

The document_extractor.py, html_export.py, and llm.py files are generic and powerful. They should be used by the new module without any changes.
This plan provides a clear, repeatable pattern for adding future standards. The first priority is the knowledge base seeding script, as the rest of the application depends on it.

Please let me know if you have any questions before you begin.

Thanks,